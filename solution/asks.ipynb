{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tDescribe briefly each of the following algorithms and its typical use cases:\n",
    "    1.\tLogistic Regression.\n",
    "    2.\tMultiple Linear Regression.\n",
    "    3.\tRandom Forest\n",
    "    4.\tXGBoost\n",
    "    5.\tGenetic Algorithms.\n",
    "    6.\tKMeans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "\n",
    "1. Logistic regression:\n",
    "    - Supervised algorithm usually used for binary classification problems. Use the logistic function to choose if an element belongs to one or another class.\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    model = LogisticRegression() \n",
    "\n",
    "2. Multiple linear regression:\n",
    "    -  Supervised algorithm to forecast a dependent value using many independent values. Inferring a linear relationship between the variables.\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    model = LinearRegression()\n",
    "\n",
    "3. Random Forest:\n",
    "    - Set of decision trees, where each one is trained with a set of data. It used for classification and forecast.\n",
    "    from sklearn.ensemble import RandomForestClassifier  \n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "4. XGBoost:\n",
    "    - Supervised algorithm based on decision trees and reinforcement learning where the trees are building sequentially and fixing the errors about the previous trees.\n",
    "    from xgboost import XGBClassifier \n",
    "    model = XGBClassifier()\n",
    "\n",
    "5. Genetic Algorithms:\n",
    "    - Optimization algorithm that receives candidate functions and evaluates each of them based on a loss function.\n",
    "6. KMeans:\n",
    "    - It is an unsupervised algorithm for data clustering based on similarities of characteristics.\n",
    "    from sklearn.cluster import KMeans\n",
    "    model = KMeans(n_clusters=3)\n",
    "    \n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tWhat is the difference between supervised and unsupervised learning algorithms?\n",
    "    1.\tDescribe the types of supervised  and unsupervised learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "\n",
    "- Supervised machine learning algorithms there are some ones in which we need to provide an input set example with the tags that we expect get in the output, to identify if the prediction is adhoc with the goal and retrain the model to reduce the error.\n",
    "    - Some examples are: RNN, Linear regression, Random forest\n",
    "\n",
    "</span>\n",
    "<span style=\"color:red\">\n",
    "\n",
    "- Unsupervised machine learning algorithms there are some ones in which we don't have an input set example with the tags that we expect get in the output. On those cases we are searching similar elements in a set of elements and identify how many groups we have.\n",
    "    - Some examples are K-Means, DBSCAN\n",
    "\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.\tAre you familiar with any techniques for algorithm evaluation and performance metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">\n",
    "- Depending of the method we can use many metrics, but some of the most used there are: \n",
    "\n",
    " - Accuracy: Number of corrected prediction over the total number of predictions.  \n",
    " - Confusion matrix: Display number of true positives, true negatives, false positives and false negatives after the classification with the predicted elements. \n",
    " - Mean squared error: Measure de error using the average squared difference between expected and predicted values. \n",
    " - Davies–Bouldin index: In clustering measure the intra-cluster distance and inter-cluster distance.\n",
    "\n",
    "</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "•\tWe would like to assess your understanding of statistical concepts.\n",
    "1.\tObserve the distribution plot of the following variable:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Texto Alternativo](sesgo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tWhat can you infer about the data's asymmetry? Would you say the distribution is symmetric, skewed to the right (positively skewed), or skewed to the left (negatively skewed)? Please provide a brief explanation of your answer based on the shape of the plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">We can't see a normal distribution, there are data with bigger frequency in the 0.0-0.4 range with a mean at point 0.2. If we consider the size of the sample, there are almost nothing data further than 0.8 point. If we had the same frequency in all the samples we had a symmetric distribution, but this is not the case.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tIn the distribution plot, what can you infer about the data's concentration? Does the distribution exhibit a pronounced peak or is it more flattened?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">We can't see a normal distribution, there are data with bigger frequency in the 0.0-0.4 range with a mean at point 0.2. If we consider the size of the sample, there are almost nothing data further than 0.8 point. If we had the same frequency in all the samples we had a symmetric distribution, but this is not the case.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        Extra points:\n",
    "1.\tAre you familiar with any technique to reduce bias in the distribution of a variable? If so, please mention the technique\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">- Sampling methods: To avoid to have classes with more samples than others, is possible to use random sampling, under sampling, under sampling, stratified sampling, searching to have the same number the examples for each class. - class weighting: Assigning weights to some classes to evaluate the loss along the training, to give preference to the lower classes.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.\tHow would you apply the technique to a DataFrame in Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\">If I need transform over a dataframe an element, I use an 'apply' function calling a lambda function or calling a function passing the row or the specific value. For example df['col'].apply(lambda x: function(x))</span>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
